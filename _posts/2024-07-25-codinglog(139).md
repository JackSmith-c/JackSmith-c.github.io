---
layout: single
title: '코딩일지(2024-07-25)'
categories:
  - Ubuntu
  - MORAI
tags:
  - shell
toc: true
toc_sticky: true
typora-root-url: ../

---







# RaspberryPi에 실시간 영상 스트리밍을 구현하다.

RaspberryPi에 실시간 영상 스트리밍을 구현하기로 했다.



## Mjpeg-streamer사용하기

이를 위해 Mjpeg-streamer를 사용하기로 했다.

해당[링크](https://velog.io/@tmdwns2127/Yolov5-%EC%8B%A4%EC%8B%9C%EA%B0%84%EA%B2%80%EC%B6%9C)를 참고하여 욜로쓰는거 이전까지 구현을 완료했다.





## 라즈베리파이에서 ImportError 해결하기

실시간 영상송출을 위해 zmq라는 라이브러리를 설치했다.

```
pip install zmq
```



그리고 `pip list`를 통해 해당 모듈이 제대로 설치된 것을 확인했다.

하지만 코드상에서 이를 임포트하려 할때, 찾을 수 없다는 오류를 발견했다.

![Code_klteJrsPM9](/images/2024-07-25-codinglog(139)/Code_klteJrsPM9.webp)



그래서 해당[링크](https://velog.io/@dogakday/%EB%9D%BC%EC%A6%88%EB%B2%A0%EB%A6%AC%ED%8C%8C%EC%9D%B4-%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%99%98%EA%B2%BD%EB%B3%80%EC%88%98-%EC%84%A4%EC%A0%95)를 참고하여 환경변수 설정을 시도하고 재부팅을 해주었다.

이후 아래 [링크](https://intstorage.tistory.com/entry/%EB%9D%BC%EC%A6%88%EB%B2%A0%EB%A6%AC%ED%8C%8C%EC%9D%B4%EC%97%90%EC%84%9C-numpy%EC%99%80-pandas-ImportError-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0-libopenblas-%EC%84%A4%EC%B9%98-%EB%B0%A9%EB%B2%95)를 참고하여 유틸리티를 하나 설치하고, 기존 webcamera라고 하는 디렉토리를 빠져나와 workspace에 test.py를 만들고 다시 실행해보니 작동했다.





## 스트리밍된 영상을 받아 객체 탐지하기

- 필요한 라이브러리 임포트

```
import cv2
import zmq
import base64
import numpy as np
import tensorflow as tf
```



- ZeroMQ 설정

```
# ZeroMQ 설정
context = zmq.Context()
footage_socket = context.socket(zmq.SUB)
footage_socket.connect('tcp://<라즈베리파이 IP>:5555')
footage_socket.setsockopt_string(zmq.SUBSCRIBE, '')

result_socket = context.socket(zmq.PUB)
result_socket.bind('tcp://*:5556')
```



- 텐서플로우 모델 로드

```
# TensorFlow 모델 로드
model = tf.saved_model.load('<모델 경로>')
```



- 메인 루프

```
while True:
    frame = footage_socket.recv()
    img = base64.b64decode(frame)
    npimg = np.frombuffer(img, dtype=np.uint8)
    source = cv2.imdecode(npimg, 1)

    # 객체 탐지 수행
    input_tensor = tf.convert_to_tensor([source])
    detections = model(input_tensor)

    # 결과 전송 (원하는 처리 추가 가능)
    _, buffer = cv2.imencode('.jpg', source)
    result_socket.send(base64.b64encode(buffer))
```



- 객체 탐지 수행

```
input_tensor = tf.convert_to_tensor([source])
detections = model(input_tensor)
```



- 결과 전송

```
_, buffer = cv2.imencode('.jpg', source)
result_socket.send(base64.b64encode(buffer))
```



위 코드의 전체적인 흐름은 다음과 같이 서술할 수 있을 것 같다.

> 라즈베리파이에서 받은 이미지를 처리하고, 처리된 결과를 다시 재전송하기

현재 나의 라즈베리파이는 핫스팟(LAN)에 물려있어서, **192.198.190.229** 로 되어 있고, 이제 모델만 선택하면 된다.

기존에 사용해봤던 **frozen_inference_graph.pb**, 이 모델은 사진에서 객체를 탐지하는 것에만 특화되어 있어서 연속적으로 송출받는 데이터를 처리하기에는 조또 부족한 성능이라고 보여져서 다른 경량화된 모델을 찾아보려고 한다.





boundingbox_v5.py파일을 만들고 `python boundingbox_v5.py`를 통해 실행했더니, 자동으로 yolov5.py모델을 만들어주더라,



![Code_7PDFX0Phh0](/images/2024-07-25-codinglog(139)/Code_7PDFX0Phh0.webp)

아직 boundingbox_v3 .py파일에 대해서 모델을 생성하지 못했다.















